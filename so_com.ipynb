{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvV1ud7AD4UGoQKJx8o+IE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somayeh1404/cod/blob/main/so_com.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBhjHFi1t36w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_FILTERS = 256\n",
        "STEP_SIZE = 20\n",
        "DROPOUT = 0.2\n",
        "LEARNING_RATE = 0.0002\n",
        "USE_BATCH_NORM = True\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "\n",
        "def setup_environment():\n",
        "\n",
        "    !pip install -q kaggle\n",
        "\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !mv kaggle.json ~/.kaggle/\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "    !kaggle datasets download -d mohamedhanyyy/chest-ctscan-images\n",
        "\n",
        "\n",
        "    with zipfile.ZipFile('chest-ctscan-images.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('dataset')\n",
        "\n",
        "\n",
        "    print(\"\\nساختار دیتاست:\")\n",
        "    !ls -R dataset | head -20\n",
        "\n",
        "\n",
        "def prepare_data():\n",
        "\n",
        "    base_path = 'dataset/Data'\n",
        "    train_path = os.path.join(base_path, 'train')\n",
        "    test_path = os.path.join(base_path, 'test')\n",
        "\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.1),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.RandomPerspective(distortion_scale=0.2, p=0.1),\n",
        "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(root=train_path, transform=train_transform)\n",
        "    test_dataset = datasets.ImageFolder(root=test_path, transform=test_transform)\n",
        "\n",
        "\n",
        "    print(\"\\nاطلاعات دیتاست آموزشی:\")\n",
        "    print(f\"تعداد کل نمونه‌ها: {len(train_dataset)}\")\n",
        "    print(f\"تعداد کلاس‌ها: {len(train_dataset.classes)}\")\n",
        "    print(f\"نام کلاس‌ها: {train_dataset.classes}\")\n",
        "    print(f\"تعداد نمونه‌های هر کلاس: {np.bincount(train_dataset.targets)}\")\n",
        "\n",
        "    print(\"\\nاطلاعات دیتاست تست:\")\n",
        "    print(f\"تعداد کل نمونه‌ها: {len(test_dataset)}\")\n",
        "    print(f\"تعداد کلاس‌ها: {len(test_dataset.classes)}\")\n",
        "    print(f\"نام کلاس‌ها: {test_dataset.classes}\")\n",
        "    print(f\"تعداد نمونه‌های هر کلاس: {np.bincount(test_dataset.targets)}\")\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "    return train_loader, test_loader, len(train_dataset.classes)\n",
        "\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, NUM_FILTERS//4, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(NUM_FILTERS//4) if USE_BATCH_NORM else nn.Identity(),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(NUM_FILTERS//4, NUM_FILTERS//2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(NUM_FILTERS//2) if USE_BATCH_NORM else nn.Identity(),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(NUM_FILTERS//2, NUM_FILTERS, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(NUM_FILTERS) if USE_BATCH_NORM else nn.Identity(),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(DROPOUT),\n",
        "            nn.Linear(NUM_FILTERS, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, test_loader, num_classes):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=0.1)\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    print(\"\\nشروع آموزش مدل:\")\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(test_loader.dataset)\n",
        "        val_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}:\")\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_accuracy:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "        if val_accuracy > best_accuracy:\n",
        "            best_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"مدل بهتر ذخیره شد با دقت: {best_accuracy:.2f}%\")\n",
        "\n",
        "    return best_accuracy\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    setup_environment()\n",
        "\n",
        "\n",
        "    train_loader, test_loader, num_classes = prepare_data()\n",
        "\n",
        "\n",
        "    model = CNNModel(num_classes=num_classes)\n",
        "\n",
        "\n",
        "    best_acc = train_model(model, train_loader, test_loader, num_classes)\n",
        "\n",
        "\n",
        "    print(f\"\\nبهترین دقت مدل روی داده تست: {best_acc:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}